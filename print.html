<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>HyperMake</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="A parameterized pipeline manager">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "light" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Introduction</a></li><li class="chapter-item expanded "><a href="install.html"><strong aria-hidden="true">1.</strong> Installation</a></li><li class="chapter-item expanded affix "><li class="part-title">Tutorial</li><li class="chapter-item expanded "><a href="tutorial/hello.html"><strong aria-hidden="true">2.</strong> Hello world!</a></li><li class="chapter-item expanded "><a href="tutorial/compose.html"><strong aria-hidden="true">3.</strong> Inputs & outputs</a></li><li class="chapter-item expanded "><a href="tutorial/branch.html"><strong aria-hidden="true">4.</strong> Parameters</a></li><li class="chapter-item expanded "><a href="tutorial/parameterized-compose.html"><strong aria-hidden="true">5.</strong> Parameterized pipelines</a></li><li class="chapter-item expanded "><a href="tutorial/subroutines.html"><strong aria-hidden="true">6.</strong> Subroutines</a></li><li class="chapter-item expanded "><a href="tutorial/modules.html"><strong aria-hidden="true">7.</strong> Modules, objects, classes</a></li><li class="chapter-item expanded "><a href="tutorial/decorators.html"><strong aria-hidden="true">8.</strong> Decorators</a></li><li class="chapter-item expanded "><a href="tutorial/packages.html"><strong aria-hidden="true">9.</strong> Packages</a></li><li class="chapter-item expanded "><a href="tutorial/filesys.html"><strong aria-hidden="true">10.</strong> File systems</a></li><li class="chapter-item expanded affix "><li class="part-title">Example pipelines</li><li class="chapter-item expanded "><a href="examples/examples.html"><strong aria-hidden="true">11.</strong> Examples</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="examples/beir.html"><strong aria-hidden="true">11.1.</strong> BEIR</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Library reference</li><li class="chapter-item expanded "><a href="stdlib/stdlib.html"><strong aria-hidden="true">12.</strong> Standard library</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="stdlib/std.html"><strong aria-hidden="true">12.1.</strong> std</a></li><li class="chapter-item expanded "><a href="stdlib/aws.html"><strong aria-hidden="true">12.2.</strong> aws</a></li><li class="chapter-item expanded "><a href="stdlib/az.html"><strong aria-hidden="true">12.3.</strong> az</a></li><li class="chapter-item expanded "><a href="stdlib/conda.html"><strong aria-hidden="true">12.4.</strong> conda</a></li><li class="chapter-item expanded "><a href="stdlib/ssh.html"><strong aria-hidden="true">12.5.</strong> ssh</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">HyperMake</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="hypermake"><a class="header" href="#hypermake">HyperMake</a></h1>
<p><code>HyperMake</code> is a parameterized pipeline definition language (think of a <code>make</code> where tasks can be parameterized) heavily inspired by <a href="https://github.com/jhclark/ducttape">Ducttape</a>.</p>
<p>It supports the following features:</p>
<ul>
<li><strong>Parameterization of tasks:</strong> a task can be of multiple versions (e.g. in a ML pipeline, a task can be of different hyperparameters)</li>
<li><strong>Minimal juggling</strong>: Inputs and outputs are just files/symlinks, and arguments are all passed as environment variables</li>
<li><strong>Automatic parallelization:</strong> based on the dependency DAG</li>
<li><strong>Cloud-agnostic:</strong> tasks can be run locally, or on a cloud (e.g. AWS, Azure), with minimal changes to the pipeline.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<h3 id="via-homebrew"><a class="header" href="#via-homebrew">Via Homebrew</a></h3>
<p>HyperMake can be installed via <a href="https://brew.sh"><code>brew</code></a> with a custom tap.</p>
<pre><code class="language-shell">brew tap ctongfei/repo
brew install --HEAD ctongfei/repo/hypermake
</code></pre>
<p>Right now the Homebrew formula is configured to use the <code>HEAD</code> version of HyperMake, which is the latest version on the <code>main</code> branch. To reinstall if the latest version changed, do</p>
<pre><code class="language-shell">brew reinstall ctongfei/repo/hypermake
</code></pre>
<h3 id="build-from-source"><a class="header" href="#build-from-source">Build from source</a></h3>
<p>HyperMake can also be directly built from source. It requires <a href="https://www.scala-sbt.org"><code>sbt</code></a> to build.</p>
<pre><code class="language-shell">git clone https://github.com/ctongfei/hypermake
cd hypermake

make
make install
</code></pre>
<p>This will build the HyperMake binary and install it locally to <code>$HOME/.local/bin/hypermake</code>.
To install it elsewhere, simply modify the <code>$PREFIX</code> variable in the <code>Makefile</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="run-a-simple-hello-world-task"><a class="header" href="#run-a-simple-hello-world-task">Run a simple "Hello, world" task</a></h1>
<p>First let's define our first task (without any inputs or outputs declared!):</p>
<pre><code class="language-shell">task hello:
  echo "Hello, world!"
</code></pre>
<p>Save this file as <code>hello.hm</code>.</p>
<blockquote>
<p>Note the syntax here: A code block starts after the <code>:</code> at the end of the task signature.
A code block is a consecutive list of <strong>indented</strong> lines of scripts, where each line must start with at least 2 spaces.</p>
</blockquote>
<p>We have created our first HyperMake script file that contains a single task.
Now let's run this task!</p>
<p>Execute the following command in your shell:</p>
<pre><code class="language-shell">  hypermake hello.hm run hello 
</code></pre>
<p>We should see the output "Hello, world!" printed in the terminal.</p>
<blockquote>
<p>The basic command line usage is <code>hypermake $script &lt;subtask&gt; $target</code>. Here the <code>&lt;subtask&gt;</code> is simply <code>run</code>.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="inputs-outputs-and-composing-tasks"><a class="header" href="#inputs-outputs-and-composing-tasks">Inputs, outputs, and composing tasks</a></h1>
<p>A task can take parameters, and yield outputs.</p>
<pre><code class="language-shell">url = "https://news.ycombinator.com"

task download(url=$) -&gt; (out="homepage.html"):
  wget $url -O $out
</code></pre>
<blockquote>
<p>Generally, when declaring a parameter whose default argument is a variable with the same name, one can omit the argument name by just writing <code>$</code>.</p>
</blockquote>
<p>Running the task <code>download</code> will download the homepage of the <a href="https://news.ycombinator.com">Hacker News</a>. Note the parameter is declared as <code>url=$</code>:
This is a shorthand for <code>url=$url</code>.</p>
<p>This task creates a single output called <code>homepage.html</code>: You can find this file at <code>out/download/default</code> directory.
One can simply write <code>out</code> instead of <code>(out="homepage.html")</code>: in this case the output file name will be <code>out</code>.</p>
<p>Now, we'd like to extract all the headlines: their URLs and titles.
We create another task that takes the output of the <code>download</code> task as input:</p>
<pre><code class="language-shell">task get_titles(html=$download.out) -&gt; out:
  cat $html \
  | perl -ne 'if (/&lt;a href="(.*?)" class="storylink"&gt;(.*?)&lt;\/a&gt;/) { print "$1\t$2\n" }' \
  &gt; $out
</code></pre>
<blockquote>
<p>Note that to refer to the output of a task, one can use the syntax <code>$taskName.$outputName</code>. Here <code>$download.out</code> is the <code>out</code> output of the <code>download</code> task.</p>
</blockquote>
<p>It creates the following pipeline:</p>
<pre class="mermaid">flowchart LR
    download --&gt; get_titles
</pre>
<p>Running the following command</p>
<pre><code class="language-shell">hypermake tutorial/ycomb.hm run get_titles
</code></pre>
<p>will sequentially run the two dependent jobs: first <code>download</code> then <code>get_titles</code>,
and the resulting TSV table will be located in <code>out/get_titles/default/out</code>.</p>
<p>In the directory <code>out/get_titles/default</code>, you can find the following files that may be of interest:</p>
<ul>
<li><code>out</code>: the resulting TSV table</li>
<li><code>script</code>: the script that was used to run the task</li>
<li><code>stdout</code>: the standard output of the task</li>
<li><code>stderr</code>: the standard error of the task</li>
<li><code>args</code>: A shell script that contains the arguments that were used to run the task</li>
<li><code>exitcode</code>: A file that contains the exit code of the task</li>
</ul>
<p>To re-run the task in shell, you can use the following command. It should behave the same as if directly running from HyperMake.</p>
<pre><code class="language-shell">. args &amp;&amp; . script
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parameters"><a class="header" href="#parameters">Parameters</a></h1>
<p>We'd like to <em>parameterize</em> our tasks: there could be multiple versions of a task.
This could be different datasets, different preprocessing pipelines, different pretrained models, etc.
Hypermake models these configurations as <strong>parameters</strong> to values and tasks.</p>
<p>For example, we are here downloading various versions of the <a href="https://nlp.stanford.edu/projects/glove/">GloVe embeddings</a>
from the Stanford NLP website:</p>
<pre><code class="language-shell">gloveUrl = {Version:
  6b="http://nlp.stanford.edu/data/glove.6B.zip"
  cc42b="http://nlp.stanford.edu/data/glove.42B.300d.zip"
  cc840b="http://nlp.stanford.edu/data/glove.840B.300d.zip"
  twitter27b="http://nlp.stanford.edu/data/glove.twitter.27B.zip"
}

task downloadGloVe(gloveUrl=$) -&gt; out:
  sleep $((( $RANDOM % 10 ) + 1))s
  wget -O glove.zip $gloveUrl
  unzip glove.zip
  mv *.txt $out
  rm glove.zip
</code></pre>
<blockquote>
<p>If the key is the same as the value, one can omit the value in the declaration, like this:
<code>{Version: 6b cc42b cc840b twitter27b}</code>.
Note that we declared a <code>Dict</code>-like object here: <code>{Version: 6b=XX cc42b=XX cc840b=XX twitter27b=XX}</code>.
This is a parameter declaration: the name of the parameter is <code>Version</code>, and it has 4 potential keys <code>6b</code>, <code>cc42b</code>, <code>cc840b</code>, and <code>twitter27b</code>.
Each key is associated with a value that follows the key (that is the URL in this example).</p>
</blockquote>
<p>Our task <code>downloadGloVe</code> is now parameterized with variable <code>Version</code>. To refer to one of these task (a <strong>case</strong>),
we can use the indexing notation <code>task[Var:key]</code>: here for example <code>downloadGloVe[Version:6b]</code>.</p>
<p>We can use the task referring expressions in the Hypermake command line interface. To download GloVe <code>6b</code> version, do</p>
<pre><code class="language-shell">hypermake glove.hm run downloadGloVe[Version:6b]
</code></pre>
<p>One can use <code>[Var:*]</code> syntax to refer to <strong>all</strong> cases of the task. The following command line invocation downloads all GloVe versions:</p>
<pre><code class="language-shell">hypermake glove.hm run 'downloadGloVe[Version: *]' -j4
</code></pre>
<blockquote>
<p>Single-quoting the task <code>downloadGlove[Version: *]</code> prohibits bash from expanding the wildcard <code>*</code> symbol.
Again, we can find the output files in <code>out/downloadGloVe/Version=XX</code>.</p>
</blockquote>
<p><code>-j $N</code> is a flag that specifies the number of parallel jobs to run. Here we run 4 jobs in parallel.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="composing-parameterized-tasks"><a class="header" href="#composing-parameterized-tasks">Composing parameterized tasks</a></h1>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="classesobjects"><a class="header" href="#classesobjects">Classes/Objects</a></h1>
<p>In Hypermake, sometimes it is needed to bundle certain definitions together so that it can be reused.
This forms an <code>object</code> (or <em>modules</em>, since a module can be seen as a singleton object):</p>
<pre><code>object my_obj:
  def x(...):
  def y(...):
  
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="decorators"><a class="header" href="#decorators">Decorators</a></h1>
<p>In Hypermake, a task can be decorated with some decorators, effectively modifying its behavior. This can support</p>
<ul>
<li>Running with different shell;</li>
<li>Running in specific virtual environments;</li>
<li>Running through some cluster submission systems;</li>
<li>etc.</li>
</ul>
<p>A decorator in HyperMake is just an object with a <code>run</code> method that takes a script as input and runs a modified version.</p>
<pre><code class="language-py">object decorator:
    def run(internal_script):
        ...
</code></pre>
<p>If a decorator admits parameters, it simply becomes a class:</p>
<pre><code class="language-py">class decorator(args):
    def run(internal_script):
        ...
</code></pre>
<p>and when applying a decorator, one could write</p>
<pre><code class="language-shell">@decorator(args)
task taskName(...) -&gt; out:
  ...
</code></pre>
<h4 id="example-1-a-decorator-that-runs-a-task-in-python"><a class="header" href="#example-1-a-decorator-that-runs-a-task-in-python">Example 1: A decorator that runs a task in Python</a></h4>
<p>An example that let us runs a task in Python instead of shell:</p>
<pre><code class="language-shell">object python:
  def run(internal_script):
    python $internal_script

@python
task helloWorldInPython:
  print("Hello World" + " " + "in Python!")
</code></pre>
<p>There is no need to define this in your pipelines: it is already available in the standard library as <code>@std.run(interpreter="python")</code>.</p>
<h4 id="example-2-decorates-a-script-to-run-in-a-conda-virtual-environment"><a class="header" href="#example-2-decorates-a-script-to-run-in-a-conda-virtual-environment">Example 2: Decorates a script to run in a Conda virtual environment</a></h4>
<p>In Python, a task can be run in different Conda virtual environments. This is a decorator that lets us do that.</p>
<pre><code class="language-shell">class conda(env):
  def run(internal_conda_script):
    eval "$(command conda 'shell.bash' 'hook' 2&gt; /dev/null)"
    conda activate $env
    . $internal_conda_script
    conda deactivate

@conda(env={Env: base myenv})
task helloWorldFromEnv:
  python -c "print('Hello World in Python from $env!')"
</code></pre>
<p>Note that in the task <code>helloWorldFromEnv</code>, the decorator <code>conda</code> has a parameterized argument: <code>env={Env: base myenv}</code>.
We can invoke both cases of the task <code>helloWorldFromEnv</code>:</p>
<pre><code class="language-shell">hypermake tutorial/decorators.hm run 'helloWorldFromEnv[Env: *]'
</code></pre>
<p>We will see both lines</p>
<pre><code>Hello World in Python from base!
Hello World in Python from myenv!
</code></pre>
<p>output to the terminal.</p>
<h4 id="example-3-chaining-decorators"><a class="header" href="#example-3-chaining-decorators">Example 3: Chaining decorators</a></h4>
<p>We have now created two decorators:</p>
<ul>
<li><code>@python</code> that executes a script using Python instead of Bash as the interpreter;</li>
<li><code>@conda</code> that runs a task in a specific Conda virtual environment.</li>
</ul>
<p>Can we compose these decorators? Yes.</p>
<pre><code class="language-python">@conda(env={Env: base myenv})
@python
task helloWorldInPythonFromEnv:
  import os
  print(f"Hello World in Python from {os.environ['env']}!")
</code></pre>
<blockquote>
<p>One can use <code>os.environ[var]</code> to get the environment variable <code>$var</code> in Python.
First, our script is wrapped by <code>@python</code>, then <code>@conda(env)</code>.
Recall that HyperMake passes parameters into the script as environment variables:
we cannot use <code>$env</code> to get the HyperMake variable in Python.</p>
</blockquote>
<h4 id="example-4-a-decorator-that-runs-a-compiled-language-c"><a class="header" href="#example-4-a-decorator-that-runs-a-compiled-language-c">Example 4: A decorator that runs a compiled language: C</a></h4>
<p>We can also create a decorator that runs a task in C. Since C is a compiled language, we need to compile the script first.</p>
<pre><code class="language-python">object gcc:
  def run(internal_c_script):
    ln -s $internal_c_script source.c
    gcc source.c -o source.out
    ./source.out
</code></pre>
<p>Now we can do fun things: write C scripts in HyperMake!</p>
<pre><code class="language-c">@gcc
task print(input="abcde"):
  #include &lt;stdio.h&gt;
  #include &lt;stdlib.h&gt;
  int main() {
    char* input = getenv("input");
    printf("%s\n", input);
    return 0;
  }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="packages"><a class="header" href="#packages">Packages</a></h1>
<p>In HyperMake, packages are special tasks that builds a software package.
They can depends on other packages but not tasks, and will be built differently on different environments (see next tutorial).</p>
<p>A package is defined as follows (note that a package can only have exactly 1 output):</p>
<pre><code>package $packageName -&gt; $packageOutputName:
  # build script
</code></pre>
<p>For example, let's build <a href="https://github.com/usnistgov/trec_eval"><code>trec_eval</code></a> (a standard information retrieval evaluation toolkit from NIST)
from its C source code:</p>
<pre><code>package trec_eval -&gt; out:
  mkdir -p $out
  git clone https://github.com/usnistgov/trec_eval $out
  cd $out
  make
</code></pre>
<p>Here we clone the repository into a HyperMake-managed directory <code>$out</code>, and then run <code>make</code> to build the package. The binary will be built in <code>$out</code>.</p>
<p>To refer to this  package output, use <code>$trec_eval</code> (there is no need to specify <code>$trec_eval.out</code>).
For example, if an evaluation task requires this package, one can write</p>
<pre><code>task eval(trec_eval=$, pred=$, gold=$) -&gt; out:
  $trec_eval/trec_eval $gold $pred &gt; $out
</code></pre>
<h4 id="example-1-copying-a-package-from-a-local-directory"><a class="header" href="#example-1-copying-a-package-from-a-local-directory">Example 1: Copying a package from a local directory</a></h4>
<pre><code class="language-bash">package pack1 -&gt; out:
  ln -s $localDir $out
</code></pre>
<p>This behavior can be written as</p>
<pre><code class="language-bash">import std
package pack1 = std.symlink(path=$localDir)
</code></pre>
<h4 id="example-2-cloning-from-a-remote-repository-and-build-it"><a class="header" href="#example-2-cloning-from-a-remote-repository-and-build-it">Example 2: Cloning from a remote repository and build it</a></h4>
<pre><code class="language-bash">package pack2(repo=$) -&gt; out:
  git clone $repo out
  cd out
  make
</code></pre>
<h4 id="example-3-creates-a-conda-environment-from-a-python-package"><a class="header" href="#example-3-creates-a-conda-environment-from-a-python-package">Example 3: Creates a Conda environment from a Python package</a></h4>
<pre><code class="language-bash">package pack3(pythonPackage=$) -&gt; out:
  mkdir -p $out
  conda env create -p $out -f $pythonPackage/environment.yml
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="file-systems"><a class="header" href="#file-systems">File systems</a></h1>
<p>A <strong>file system</strong> encapsulates the operations that can be performed on files and directories in a particular environment in HyperMake.</p>
<p>HyperMake provides a default file system implementation for the local file system (<code>local</code>),
and has utilities to define file systems over common remote systems such as SFTP, AWS S3, and Azure Blob Storage.</p>
<p>Additionally, it is possible to define custom file systems for different environments.</p>
<p>In HyperMake, a file system is an <em>object</em> with various member functions defined.</p>
<h3 id="functions-in-a-file-system-object"><a class="header" href="#functions-in-a-file-system-object">Functions in a file system object</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Member</th><th>Description</th></tr></thead><tbody>
<tr><td><code>fs.root</code></td><td>A string specifying the root path of all HyperMake outputs.</td></tr>
<tr><td><code>fs.read(file)</code></td><td>Reads the file <code>$file</code> and outputs the content to <code>stdout</code>.</td></tr>
<tr><td><code>fs.mkdir(dir)</code></td><td>Creates an empty directory <code>$dir</code>. <br> This should have the semantics of <code>mkdir -p</code>: it should create all parent <br> directories if they do not exist, and it should not fail if the directory <br> already exists.</td></tr>
<tr><td><code>fs.exists(file)</code></td><td>Checks if <code>$file</code> exists in <code>fs</code>.</td></tr>
<tr><td><code>fs.link(src, dst)</code></td><td>Creates a symbolic link at <code>$dst</code> that links to <code>$src</code>.</td></tr>
<tr><td><code>fs.touch(file)</code></td><td>Creates an empty file at path `$file</td></tr>
<tr><td><code>fs.remove(file)</code></td><td>Removes file <code>$file</code> in <code>fs</code>. <br> If <code>$file</code> is a directory, it should remove the directory and all its contents.</td></tr>
<tr><td><code>fs.upload(src, dst)</code></td><td>Uploads the file or directory <code>$src</code> in <code>local</code> to <code>$dst</code> in <code>fs</code>.</td></tr>
<tr><td><code>fs.download(src, dst)</code></td><td>Downloads the file or directory <code>$src</code> in <code>fs</code> to <code>$dst</code> in <code>local</code>.</td></tr>
<tr><td><code>fs.execute(command)</code></td><td><strong>(Optional)</strong> Executes the command <code>$command</code> in <code>fs</code>'s shell. <br> This can be omitted if the file system does not support running commands.</td></tr>
</tbody></table>
</div>
<p>There is no need to define <code>local</code> as it is internal to HyperMake. A reference implementation of <code>local</code> is provided below.</p>
<pre><code class="language-py">object local:
    root = "."
    
    def read(file):
        cat $file
    
    def mkdir(dir):
        mkdir -p $dir
    
    def exists(file):
        test -e $file
    
    def link(src, dst):
        ln -s $src $dst
    
    def touch(file):
        touch $file
    
    def remove(file):
        rm -r $file
       
    def upload(src, dst):
        ln -s $src $dst  # both local, so a symbolic link suffices
    
    def download(src, dst):
        ln -s $src $dst  # both local, so a symbolic link suffices
        
    def execute(command):
        bash -e $command
</code></pre>
<h4 id="example-define-a-file-system-over-sftp"><a class="header" href="#example-define-a-file-system-over-sftp">Example: define a file system over SFTP</a></h4>
<pre><code class="language-sh">import ssh
object my_server = ssh.server(host="...")
</code></pre>
<h4 id="example-define-a-file-system-over-aws-s3"><a class="header" href="#example-define-a-file-system-over-aws-s3">Example: define a file system over AWS S3</a></h4>
<pre><code class="language-sh">import aws
object my_bucket = aws.s3(name="...")
</code></pre>
<h4 id="example-define-a-file-system-over-azure-blob-storage"><a class="header" href="#example-define-a-file-system-over-azure-blob-storage">Example: define a file system over Azure Blob Storage</a></h4>
<pre><code class="language-sh">import az
object my_container = az.storage_blob(name="...")
</code></pre>
<h3 id="transferring-file-between-environments"><a class="header" href="#transferring-file-between-environments">Transferring file between environments</a></h3>
<p>Sometimes different parts of a pipeline are run under different environments,
e.g., data preprocessing may happen on a local machine, whereas training is done on an SSH grid, or
on AWS EC2 or Azure ML.</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>We showcase an example pipeline of running the <a href="https://beir.ai">BEIR</a> (<a href="https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/hash/65b9eea6e1cc6bb9f0cd2a47751a186f-Abstract-round2.html">paper</a>) benchmark in HyperMake.</p>
<p>BEIR is a robust and heterogeneous evaluation benchmark for zero-shot information retrieval. It includes a diverse set of retrieval tasks, such as web search, question answering, and entity retrieval. The benchmark is designed to evaluate the generalization capabilities of retrieval models across different tasks and domains.</p>
<p>In this example, we run the standard BM25 lexical retrieval model (with <a href="https://github.com/castorini/pyserini">Pyserini</a>) on the BEIR-14 subset (those with public licenses), evaluated with the standard <a href="https://github.com/usnistgov/trec_eval"><code>trec_eval</code></a> evaluation tool.</p>
<p>First, let's import some modules to simplify the pipeline definition:</p>
<pre><code class="language-bash">import conda
import std
</code></pre>
<p>Next, we define some hyperparameters for the pipeline.</p>
<p>BEIR-14 datasets, defined as a HyperMake variable:</p>
<pre><code class="language-bash">beir_dataset = {BeirDataset:
  msmarco trec-covid nfcorpus nq hotpotqa fiqa
  arguana webis-touche2020 quora dbpedia-entity
  scidocs fever climate-fever scifact
}
</code></pre>
<p>Partition of the datasets that we want to evaluate (MSMARCO is evaluated on the <code>dev</code> set), defined as a HyperMake dict:</p>
<pre><code class="language-bash">test_partition = {BeirDataset:
  msmarco=dev trec-covid=test nfcorpus=test nq=test hotpotqa=test fiqa=test
  arguana=test webis-touche2020=test quora=test dbpedia-entity=test
  scidocs=test fever=test climate-fever=test scifact=test
}
</code></pre>
<p>And a constant for the data downloading URL prefix:</p>
<pre><code class="language-bash">beir_url_prefix = "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets"
</code></pre>
<h3 id="step-1-build-the-trec_eval-tool"><a class="header" href="#step-1-build-the-trec_eval-tool">Step 1: Build the <code>trec_eval</code> tool</a></h3>
<pre><code class="language-bash">package trec_eval -&gt; out:
  git clone https://github.com/usnistgov/trec_eval.git $out
  cd $out
  make
</code></pre>
<h3 id="step-2-build-our-conda-environment-for-pyserini"><a class="header" href="#step-2-build-our-conda-environment-for-pyserini">Step 2: Build our Conda environment for Pyserini</a></h3>
<pre><code class="language-bash">package pyserini = conda.create(
  args="-c conda-forge python=3.10 openjdk=21",
  extra_pip_packages="torch faiss-cpu pyserini"
)
</code></pre>
<p>Note that both of these steps are <em>packages</em> instead of <code>tasks</code>: these are platform-dependent and should be built for each platform separately.</p>
<h3 id="step-3-download-the-beir-datasets"><a class="header" href="#step-3-download-the-beir-datasets">Step 3: Download the BEIR datasets</a></h3>
<pre><code class="language-bash">task raw_beir_data(beir_dataset=$, beir_url_prefix=$) -&gt; out:
  wget -O dataset.zip $beir_url_prefix/$beir_dataset.zip
  unzip dataset.zip
  rm dataset.zip
  mv $beir_dataset out
</code></pre>
<h3 id="step-4-convert-the-beir-datasets-to-standard-trec-format"><a class="header" href="#step-4-convert-the-beir-datasets-to-standard-trec-format">Step 4: Convert the BEIR datasets to standard TREC format</a></h3>
<p>Here Python code is embedded directly in the task definition with <code>std.run</code> as an example, showing how to use Python code directly in the task definition.  This is useful for small scripts that are not worth putting in a separate file.  This script is actually large enough that it would be better to put it in a separate file, but for the sake of demonstration, we include it here.</p>
<p>Note the use of <code>@conda.activate</code> to run this task in the Pyserini environment we created earlier.</p>
<pre><code class="language-python">@conda.activate(environment=$pyserini)
@std.run(interpreter="python")
task beir_to_trec(data=$raw_beir_data.out) -&gt; out:
  import os
  import json
  import sys
  import csv
  from tqdm import tqdm
  data = os.environ['data']  # HyperMake variables are sent as environment variables
  out = os.environ['out']
  os.mkdir(out)
  with open(f"{data}/corpus.jsonl") as f_in, open(f"{out}/corpus", 'w') as f_out:
    for line in tqdm(f_in):
      obj = json.loads(line)
      id = obj['_id']
      text = obj['text'].replace('\n', ' ').replace('\t', ' ').replace('\r', ' ')
      title = obj.get('title', "")
      trec_line = f"{id}\t{title}: {text}" if title != "" else f"{id}\t{text}" 
      # Concatenate title and text
      print(trec_line, file=f_out)
  queries = {}
  with open(f"{data}/queries.jsonl") as f:
    for line in tqdm(f):
      obj = json.loads(line)
      id = obj['_id']
      text = obj['text']
      queries[id] = text
  for partition in os.listdir(f"{data}/qrels"):
    partition = os.path.splitext(partition)[0]
    with open(f"{data}/qrels/{partition}.tsv") as f_in, open(f"{out}/{partition}.qrels", 'w') as f_out:
      query_ids = set()
      for row in tqdm(csv.DictReader(f_in, delimiter='\t')):
        query_ids.add(row['query-id'])
        print(f"{row['query-id']}\t0\t{row['corpus-id']}\t{row['score']}", file=f_out)
    with open(f"{out}/{partition}.queries", 'w') as f:
      for query_id in query_ids:
        print(f"{query_id}\t{queries[query_id]}", file=f)
</code></pre>
<h3 id="step-5-index-the-corpus-with-pyserini"><a class="header" href="#step-5-index-the-corpus-with-pyserini">Step 5: Index the corpus with Pyserini</a></h3>
<p>At this step, we run a Bash script under the Pyserini conda environment.</p>
<pre><code class="language-bash">@conda.activate(environment=$pyserini)
task index(data=$beir_to_trec.out) -&gt; out:
  mkdir corpus
  cat $data/corpus \
    | jq -Rc 'inputs | split("\t") | {id: .[0], contents: .[1]}' \
    &gt; corpus/corpus.json  # Convert TREC format to Pyserini JSON
  python -m pyserini.index.lucene \
    --collection JsonCollection \
    --input corpus \
    --index $out \
    --generator DefaultLuceneDocumentGenerator \
    --threads $(nproc) \
    --storePositions \
    --storeDocvectors \
    --storeRaw
</code></pre>
<h3 id="step-6-run-bm25-retrieval-with-pyserini"><a class="header" href="#step-6-run-bm25-retrieval-with-pyserini">Step 6: Run BM25 retrieval with Pyserini</a></h3>
<p>Again, this is run under the Pyserini conda environment.</p>
<pre><code class="language-bash">@conda.activate(environment=$pyserini)
task retrieve(
  data=$beir_to_trec.out, 
  test_partition=$, 
  index=$index.out
) -&gt; (out="result.qres"):
  ln -s $data/$test_partition.queries test.tsv
  python -m pyserini.search.lucene \
    --index $index \
    --topics test.tsv \
    --output $out \
    --batch-size 32 \
    --hits 100 \
    --threads $(nproc) \
    --remove-duplicates --remove-query --bm25
</code></pre>
<h3 id="step-7-evaluate-the-retrieval-results-with-trec_eval"><a class="header" href="#step-7-evaluate-the-retrieval-results-with-trec_eval">Step 7: Evaluate the retrieval results with <code>trec_eval</code></a></h3>
<pre><code class="language-bash">task evaluate(
  data=$beir_to_trec.out,
  result=$retrieve.out,
  test_partition=$,
  trec_eval=$
) -&gt; (out="eval.txt"):
  $trec_eval/trec_eval -m all_trec $data/$test_partition.qrels $result &gt; $out
</code></pre>
<h3 id="step-8-aggregate-the-evaluation-results-over-all-datasets-in-beir-14"><a class="header" href="#step-8-aggregate-the-evaluation-results-over-all-datasets-in-beir-14">Step 8: Aggregate the evaluation results over all datasets in BEIR-14</a></h3>
<p>Assume that we care about <code>map</code>, <code>recall_100</code>, and <code>ndcg_cut_10</code> metrics from <code>trec_eval</code>.</p>
<pre><code class="language-bash">metric = {Metric: map recall_100 ndcg_cut_10}
</code></pre>
<p>And now we aggregate the results over all datasets with <code>[BeirDataset: *]</code> in HyperMake:</p>
<pre><code class="language-bash">task aggregate_metric(
  eval_results=$evaluate[BeirDataset: *].out, 
  metric=$
) -&gt; (out="aggregate.txt"):
  grep -E "^$metric " $eval_results/* &gt; $out
</code></pre>
<h3 id="run-the-pipeline"><a class="header" href="#run-the-pipeline">Run the pipeline</a></h3>
<p>Now the full pipeline definition (<code>beir.hm</code>) is complete.</p>
<p>Let's preview the pipeline with <code>hypermake list</code>:</p>
<pre><code class="language-bash">hypermake beir.hm list
</code></pre>
<p>It shows the nice DAG structure of our pipeline:</p>
<pre><code>HyperMake 0.1.0 -- A parameterized workflow manager
Workflow file: beir.hm

Variables:
  • Metric: { map recall_100 ndcg_cut_10 }
  • BeirDataset: { msmarco scifact trec-covid webis-touche2020 fiqa dbpedia-entity fever nfcorpus hotpotqa climate-fever scidocs nq quora arguana }

Tasks:
  • pyserini@local
  │ • raw_beir_data[BeirDataset]
  │ │ • trec_eval@local
  ├─┴─│─• beir_to_trec[BeirDataset]
  ├───│─┼─• index[BeirDataset]
  └───│─┼─┴─• retrieve[BeirDataset]
      └─┴───┴─• evaluate[BeirDataset]
              └─• aggregate_metric[Metric]
</code></pre>
<p>We can run the pipeline with the following command:</p>
<pre><code class="language-bash">hypermake beir.hm run "aggregate_metric[Metric: *]" -j8
</code></pre>
<p>Here we compute the <code>aggregate_metric</code> task for all metrics defined in <code>metric</code>, with max 8 jobs running in parallel!</p>
<p>The results should match the results in Table 2 (BM25 column) of the <a href="https://arxiv.org/pdf/2310.08319">RepLlama paper</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="module-std"><a class="header" href="#module-std">Module <code>std</code></a></h1>
<p>Contains some miscellaneous utilities for HyperMake.</p>
<h2 id="function-stdsymlink"><a class="header" href="#function-stdsymlink">Function <code>std.symlink</code></a></h2>
<p>Creates a symbolic link as an output. This is particularly useful when referring to a local repository that is under development.</p>
<pre><code class="language-py">import std
package my_repo = std.symlink(path="path/to/my/repo")
</code></pre>
<h2 id="class-stdrun"><a class="header" href="#class-stdrun">Class <code>std.run</code></a></h2>
<p>Enables a task in HyperMake to run in a custom interpreter (e.g. Python, Perl, etc.).</p>
<p>Example usage:</p>
<pre><code class="language-py">import std

sender = {Sender: Alice Bob}

@std.run(interpreter="python3")
task hello_world(sender=$):
    import os
    print(f"Hello, world from {os.environ["sender"]}!")
</code></pre>
<p>Note that whatever interpreter you choose to use, HyperMake parameters are passed into the task as <strong>environment variables</strong>. Here in Python we use <code>os.environ</code> to access them.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="module-aws"><a class="header" href="#module-aws">Module <code>aws</code></a></h1>
<h2 id="awss3"><a class="header" href="#awss3"><code>aws.s3</code></a></h2>
<p>Enables AWS S3 buckets as a HyperMake file system. Behind the scenes it uses the <code>aws s3</code> CLI command family.</p>
<p>Example usage:</p>
<pre><code class="language-python">import aws
object my_bucket = aws.s3(
    bucket="my_bucket",
    root=""
)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="module-az"><a class="header" href="#module-az">Module <code>az</code></a></h1>
<p>Enables various decorators for Microsoft Azure services in HyperMake.</p>
<h2 id="azstorage_blob"><a class="header" href="#azstorage_blob"><code>az.storage_blob</code></a></h2>
<p>Enables Azure Blob Storage containers to be used as a file system in HyperMake. Behind the scenes it uses the <code>az storage blob</code> CLI command family.</p>
<p>Example usage:</p>
<pre><code class="language-py">import az 
object az_storage = az.storage_blob( 
    container="my_container", 
    extra_args="--account-name xxx --account-key yyy"
)

data_path = "/path/to/data"@az_storage
</code></pre>
<h2 id="azstorage_fs"><a class="header" href="#azstorage_fs"><code>az.storage_fs</code></a></h2>
<p>Enables Azure Data Lake Storage (ADLS) Gen2 containers to be used as a file system in HyperMake. Behind the scenes it uses the <code>az storage fs</code> CLI command family.</p>
<h2 id="azml_job_create"><a class="header" href="#azml_job_create"><code>az.ml_job_create</code></a></h2>
<p>Enables Azure ML command jobs as a submitter in HyperMake. Behind the scenes it uses the <code>az ml job</code> CLI command family.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="module-conda"><a class="header" href="#module-conda">Module <code>conda</code></a></h1>
<p>Enables Conda environments to be used as decorators in HyperMake.</p>
<h2 id="function-condacreate_env"><a class="header" href="#function-condacreate_env">Function <code>conda.create_env</code></a></h2>
<p>Creates a Conda environment based on a yaml specification file.</p>
<pre><code class="language-python">package env = conda.create_env(file="environment.yml")
</code></pre>
<h2 id="class-condaactivate"><a class="header" href="#class-condaactivate">Class <code>conda.activate</code></a></h2>
<p>Enables a job to be run within a Conda environment.</p>
<pre><code class="language-python">import conda

@conda.activate(environment="myenv")
task check_if_cuda_is_available():
    python -c "import torch; print(torch.cuda.is_available())"
</code></pre>
<p>You can use the returned path of <code>conda.create_env</code> as the <code>environment</code> argument.</p>
<pre><code class="language-python">package env = conda.create_env(file="environment.yml")
@conda.activate(environment=$env)
</code></pre>
<p>This can even be expressed with nested decorators:</p>
<pre><code class="language-python">import std
import conda

@conda.activate(environment="myenv")
@std.run(interpreter="python")
task check_if_cuda_is_available():
    import torch
    print(torch.cuda.is_available())
</code></pre>
<p>Here we first wrap the script with a <code>python</code> interpreter, then dictate that this task should run within a Conda environment.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="module-ssh"><a class="header" href="#module-ssh">Module <code>ssh</code></a></h1>
<p>Enables SSH servers to be used as file systems in HyperMake.</p>
<h2 id="sshserver"><a class="header" href="#sshserver"><code>ssh.Server</code></a></h2>
<p>Defines a SSH server in HyperMake. Note that this file system is able to execute jobs.</p>
<p>Example:</p>
<pre><code class="language-py">import ssh
object my_server = ssh.server(
    host='192.168.0.7',    # host name, in ~/.ssh/config
    root='/home/user/out'  # root of HyperMake output on the remote server
)

task my_remote_task@my_server(input@server) -&gt; output@my_server:
    # This task will be executed on the remote server
    # and the input will be copied to the remote server.
    # The output is expected to appear on the remote server.
    ...
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
