import conda
import std

local.root = "/home/tongfei/data/beir"

# This is the BEIR-14 subset.
beir_dataset = {BeirDataset:
  msmarco trec-covid nfcorpus nq hotpotqa fiqa
  arguana webis-touche2020 quora dbpedia-entity
  scidocs fever climate-fever scifact
}

# This is the partition of the BEIR-14 subset that we want to evaluate on.
test_partition = {BeirDataset:
  msmarco=dev trec-covid=test nfcorpus=test nq=test hotpotqa=test fiqa=test
  arguana=test webis-touche2020=test quora=test dbpedia-entity=test
  scidocs=test fever=test climate-fever=test scifact=test
}

beir_url_prefix = "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets"

# Builds the trec_eval tool from source.
package trec_eval -> out:
  git clone https://github.com/usnistgov/trec_eval.git $out
  cd $out
  make

# Creates a conda environment that contains the pyserini package.
package pyserini = conda.create(
  args="-c conda-forge python=3.10 openjdk=21",
  extra_pip_packages="torch faiss-cpu pyserini"
)

# Downloads the BEIR-14 subset of the BEIR test suite.
task raw_beir_data(beir_dataset=$, beir_url_prefix=$) -> out:
  wget -O dataset.zip $beir_url_prefix/$beir_dataset.zip
  unzip dataset.zip
  rm dataset.zip
  mv $beir_dataset out

# Converts the BEIR-14 subset to the standard TREC format.
# Here Python code is embedded directly in the task definition with `std.run(interpreter="python")`
# as an example, showing how to use Python code directly in the task definition.
# This is useful for small scripts that are not worth putting in a separate file.
# This script is actually large enough that it would be better to put it in a separate file,
# but for the sake of demonstration, we include it here.
@conda.activate(environment=$pyserini)
@std.run(interpreter="python")
task beir_to_trec(data=$raw_beir_data.out) -> out:
  import os
  import json
  import sys
  import csv
  from tqdm import tqdm
  data = os.environ['data']
  out = os.environ['out']
  os.mkdir(out)
  with open(f"{data}/corpus.jsonl") as f_in, open(f"{out}/corpus", 'w') as f_out:
    for line in tqdm(f_in):
      obj = json.loads(line)
      id = obj['_id']
      text = obj['text'].replace('\n', ' ').replace('\t', ' ').replace('\r', ' ')
      title = obj.get('title', "")
      trec_line = f"{id}\t{title}: {text}" if title != "" else f"{id}\t{text}"  # Concatenate title and text
      print(trec_line, file=f_out)
  queries = {}
  with open(f"{data}/queries.jsonl") as f:
    for line in tqdm(f):
      obj = json.loads(line)
      id = obj['_id']
      text = obj['text']
      queries[id] = text
  for partition in os.listdir(f"{data}/qrels"):
    partition = os.path.splitext(partition)[0]
    with open(f"{data}/qrels/{partition}.tsv") as f_in, open(f"{out}/{partition}.qrels", 'w') as f_out:
      query_ids = set()
      for row in tqdm(csv.DictReader(f_in, delimiter='\t')):
        query_ids.add(row['query-id'])
        print(f"{row['query-id']}\t0\t{row['corpus-id']}\t{row['score']}", file=f_out)
    with open(f"{out}/{partition}.queries", 'w') as f:
      for query_id in query_ids:
        print(f"{query_id}\t{queries[query_id]}", file=f)

# Indexes the corpora using Pyserini.
@conda.activate(environment=$pyserini)
task index(data=$beir_to_trec.out) -> out:
  mkdir corpus
  cat $data/corpus \
    | jq -Rc 'inputs | split("\t") | {id: .[0], contents: .[1]}' \
    > corpus/corpus.json  # Convert TREC format to Pyserini JSON
  python -m pyserini.index.lucene \
    --collection JsonCollection \
    --input corpus \
    --index $out \
    --generator DefaultLuceneDocumentGenerator \
    --threads $(nproc) \
    --storePositions \
    --storeDocvectors \
    --storeRaw

# Retrieves the top 100 documents for each query with Pyserini.
@conda.activate(environment=$pyserini)
task retrieve(data=$beir_to_trec.out, test_partition=$, index=$index.out) -> (out="result.qres"):
  ln -s $data/$test_partition.queries test.tsv
  python -m pyserini.search.lucene \
    --index $index \
    --topics test.tsv \
    --output $out \
    --batch-size 32 \
    --hits 100 \
    --threads $(nproc) \
    --remove-duplicates --remove-query --bm25

# Evaluates the retrieval results using trec_eval.
task evaluate(
  data=$beir_to_trec.out,
  result=$retrieve.out,
  test_partition=$,
  trec_eval=$
) -> (out="eval.txt"):
  $trec_eval/trec_eval -m all_trec $data/$test_partition.qrels $result > $out

metric = {Metric:
  map recall_100 ndcg_cut_10
}

# Aggregates the evaluation results over all BEIR-14 datasets for each metric.
task aggregate_metric(eval_results=$evaluate[BeirDataset: *].out, metric=$) -> (out="aggregate.txt"):
  grep -E "^$metric " $eval_results/* > $out

plan Run = {
  aggregate_metric[Metric: *]
}
